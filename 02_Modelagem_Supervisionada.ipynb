{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "\n",
    "# Modelos de Classificação\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Modelos de Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Balanceamento\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Configurações\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Seed para reprodutibilidade\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65449fbf",
   "metadata": {},
   "source": [
    "## 2.1 Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe36a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "print(\"Carregando dados...\")\n",
    "flights = pd.read_csv('flights.csv')\n",
    "airlines = pd.read_csv('airlines.csv')\n",
    "airports = pd.read_csv('airports.csv')\n",
    "\n",
    "print(f\"Shape dos dados: {flights.shape}\")\n",
    "print(f\"\\nColunas disponíveis:\")\n",
    "print(flights.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079dcbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostragem para facilitar processamento (opcional)\n",
    "# Se o dataset for muito grande, podemos usar uma amostra\n",
    "SAMPLE_SIZE = None  # None para usar todos os dados, ou um número como 100000\n",
    "\n",
    "if SAMPLE_SIZE and len(flights) > SAMPLE_SIZE:\n",
    "    print(f\"Usando amostra de {SAMPLE_SIZE:,} registros\")\n",
    "    flights_sample = flights.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE)\n",
    "else:\n",
    "    print(\"Usando dataset completo\")\n",
    "    flights_sample = flights.copy()\n",
    "\n",
    "print(f\"Shape final: {flights_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e2dbe",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8336f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novas features\n",
    "print(\"Criando novas features...\")\n",
    "\n",
    "df = flights_sample.copy()\n",
    "\n",
    "# 1. Variável alvo para classificação: atraso sim/não\n",
    "if 'ARRIVAL_DELAY' in df.columns:\n",
    "    df['IS_DELAYED'] = (df['ARRIVAL_DELAY'] > 15).astype(int)  # >15 min = atraso\n",
    "    print(f\"✓ Variável IS_DELAYED criada\")\n",
    "    print(f\"  Voos atrasados: {df['IS_DELAYED'].sum():,} ({(df['IS_DELAYED'].mean()*100):.2f}%)\")\n",
    "\n",
    "# 2. Período do dia\n",
    "if 'SCHEDULED_DEPARTURE' in df.columns:\n",
    "    df['DEPARTURE_HOUR'] = df['SCHEDULED_DEPARTURE'] // 100\n",
    "    df['DEPARTURE_PERIOD'] = pd.cut(df['DEPARTURE_HOUR'], \n",
    "                                    bins=[0, 6, 12, 18, 24],\n",
    "                                    labels=['Madrugada', 'Manhã', 'Tarde', 'Noite'])\n",
    "    print(f\"✓ Período do dia criado\")\n",
    "\n",
    "# 3. Final de semana\n",
    "if 'DAY_OF_WEEK' in df.columns:\n",
    "    df['IS_WEEKEND'] = df['DAY_OF_WEEK'].isin([6, 7]).astype(int)\n",
    "    print(f\"✓ Indicador de final de semana criado\")\n",
    "\n",
    "# 4. Trimestre/Estação do ano\n",
    "if 'MONTH' in df.columns:\n",
    "    df['QUARTER'] = pd.cut(df['MONTH'], \n",
    "                           bins=[0, 3, 6, 9, 12],\n",
    "                           labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    \n",
    "    # Estação do ano (Hemisfério Norte)\n",
    "    season_map = {1: 'Inverno', 2: 'Inverno', 3: 'Primavera', 4: 'Primavera',\n",
    "                  5: 'Primavera', 6: 'Verão', 7: 'Verão', 8: 'Verão',\n",
    "                  9: 'Outono', 10: 'Outono', 11: 'Outono', 12: 'Inverno'}\n",
    "    df['SEASON'] = df['MONTH'].map(season_map)\n",
    "    print(f\"✓ Trimestre e estação do ano criados\")\n",
    "\n",
    "# 5. Categoria de distância\n",
    "if 'DISTANCE' in df.columns:\n",
    "    df['DISTANCE_CATEGORY'] = pd.cut(df['DISTANCE'],\n",
    "                                     bins=[0, 500, 1000, 2000, 5000],\n",
    "                                     labels=['Curta', 'Média', 'Longa', 'Muito_Longa'])\n",
    "    print(f\"✓ Categoria de distância criada\")\n",
    "\n",
    "# 6. Tempo de voo programado\n",
    "if 'SCHEDULED_ARRIVAL' in df.columns and 'SCHEDULED_DEPARTURE' in df.columns:\n",
    "    # Converter para minutos\n",
    "    dep_minutes = (df['SCHEDULED_DEPARTURE'] // 100) * 60 + (df['SCHEDULED_DEPARTURE'] % 100)\n",
    "    arr_minutes = (df['SCHEDULED_ARRIVAL'] // 100) * 60 + (df['SCHEDULED_ARRIVAL'] % 100)\n",
    "    df['SCHEDULED_FLIGHT_TIME'] = arr_minutes - dep_minutes\n",
    "    # Ajustar para voos que cruzam a meia-noite\n",
    "    df.loc[df['SCHEDULED_FLIGHT_TIME'] < 0, 'SCHEDULED_FLIGHT_TIME'] += 1440\n",
    "    print(f\"✓ Tempo de voo programado calculado\")\n",
    "\n",
    "print(f\"\\nShape após feature engineering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b85318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição da variável alvo\n",
    "if 'IS_DELAYED' in df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Contagem\n",
    "    df['IS_DELAYED'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Distribuição de Voos: Atrasados vs Pontuais', fontweight='bold')\n",
    "    axes[0].set_xlabel('0 = Pontual, 1 = Atrasado')\n",
    "    axes[0].set_ylabel('Contagem')\n",
    "    axes[0].set_xticklabels(['Pontual', 'Atrasado'], rotation=0)\n",
    "    \n",
    "    # Percentual\n",
    "    df['IS_DELAYED'].value_counts(normalize=True).plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "    axes[1].set_title('Proporção de Atrasos', fontweight='bold')\n",
    "    axes[1].set_ylabel('')\n",
    "    axes[1].legend(['Pontual', 'Atrasado'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1260b7d",
   "metadata": {},
   "source": [
    "## 2.3 Preparação dos Dados para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar features para o modelo\n",
    "print(\"Selecionando features...\")\n",
    "\n",
    "# Features numéricas\n",
    "numeric_features = ['MONTH', 'DAY', 'DAY_OF_WEEK', 'DEPARTURE_HOUR', 'DISTANCE', \n",
    "                   'SCHEDULED_FLIGHT_TIME', 'IS_WEEKEND']\n",
    "\n",
    "# Features categóricas\n",
    "categorical_features = ['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
    "                       'DEPARTURE_PERIOD', 'QUARTER', 'SEASON', 'DISTANCE_CATEGORY']\n",
    "\n",
    "# Verificar quais features existem\n",
    "numeric_features = [f for f in numeric_features if f in df.columns]\n",
    "categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "\n",
    "print(f\"Features numéricas: {numeric_features}\")\n",
    "print(f\"Features categóricas: {categorical_features}\")\n",
    "\n",
    "# Criar dataset para modelagem\n",
    "all_features = numeric_features + categorical_features\n",
    "df_model = df[all_features + ['IS_DELAYED', 'ARRIVAL_DELAY']].copy()\n",
    "\n",
    "# Remover linhas com NaN na variável alvo\n",
    "df_model = df_model.dropna(subset=['IS_DELAYED', 'ARRIVAL_DELAY'])\n",
    "\n",
    "print(f\"\\nShape para modelagem: {df_model.shape}\")\n",
    "print(f\"Missing values por coluna:\")\n",
    "print(df_model.isnull().sum()[df_model.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding de variáveis categóricas\n",
    "print(\"Aplicando encoding...\")\n",
    "\n",
    "df_encoded = df_model.copy()\n",
    "\n",
    "# Label Encoding para variáveis categóricas\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    if col in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Preencher NaN com uma categoria especial\n",
    "        df_encoded[col] = df_encoded[col].fillna('MISSING')\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"✓ {col}: {len(le.classes_)} categorias\")\n",
    "\n",
    "# Preencher NaN em features numéricas com mediana\n",
    "for col in numeric_features:\n",
    "    if col in df_encoded.columns:\n",
    "        if df_encoded[col].isnull().sum() > 0:\n",
    "            median_val = df_encoded[col].median()\n",
    "            df_encoded[col].fillna(median_val, inplace=True)\n",
    "            print(f\"✓ {col}: preenchido com mediana = {median_val}\")\n",
    "\n",
    "print(f\"\\nShape final: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34821a7d",
   "metadata": {},
   "source": [
    "## 2.4 Modelagem de Classificação: Prever se Voo vai Atrasar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para classificação\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELAGEM DE CLASSIFICAÇÃO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Separar features e target\n",
    "X = df_encoded[numeric_features + categorical_features]\n",
    "y = df_encoded['IS_DELAYED']\n",
    "\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"\\nDistribuição da variável alvo:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nProporção de classes:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n✓ Dados normalizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos de classificação\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=RANDOM_STATE, verbose=-1)\n",
    "}\n",
    "\n",
    "print(f\"Modelos a serem treinados: {list(classifiers.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f43749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar e avaliar modelos\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "results_classification = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Treinando: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Treinar\n",
    "    if name == 'Logistic Regression':\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results_classification[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'model': clf,\n",
    "        'predictions': y_pred,\n",
    "        'predictions_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    print(f\"\\nMatriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n✓ Todos os modelos treinados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação de modelos\n",
    "comparison_df = pd.DataFrame(results_classification).T\n",
    "comparison_df = comparison_df[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAÇÃO DE MODELOS - CLASSIFICAÇÃO\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Visualização\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gráfico de barras\n",
    "comparison_df.plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Comparação de Métricas - Modelos de Classificação', fontweight='bold', fontsize=14)\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_xlabel('Modelo')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].set_xticklabels(comparison_df.index, rotation=45, ha='right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(comparison_df, annot=True, fmt='.3f', cmap='YlGnBu', ax=axes[1])\n",
    "axes[1].set_title('Heatmap de Métricas', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7780f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name in results_classification.keys():\n",
    "    fpr, tpr, _ = roc_curve(y_test, results_classification[name]['predictions_proba'])\n",
    "    auc = results_classification[name]['ROC-AUC']\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Comparação de Modelos', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (para modelos baseados em árvore)\n",
    "best_model_name = comparison_df['F1-Score'].idxmax()\n",
    "best_model = results_classification[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nMelhor modelo (por F1-Score): {best_model_name}\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': numeric_features + categorical_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Features Mais Importantes:\")\n",
    "    print(feature_importance.head(15))\n",
    "    \n",
    "    # Visualização\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(15), feature_importance['Importance'].head(15))\n",
    "    plt.yticks(range(15), feature_importance['Feature'].head(15))\n",
    "    plt.xlabel('Importância')\n",
    "    plt.title(f'Top 15 Features - {best_model_name}', fontweight='bold', fontsize=14)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e728d",
   "metadata": {},
   "source": [
    "## 2.5 Modelagem de Regressão: Prever Tempo de Atraso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para regressão\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELAGEM DE REGRESSÃO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filtrar apenas voos atrasados para regressão\n",
    "df_delayed = df_encoded[df_encoded['IS_DELAYED'] == 1].copy()\n",
    "\n",
    "X_reg = df_delayed[numeric_features + categorical_features]\n",
    "y_reg = df_delayed['ARRIVAL_DELAY']\n",
    "\n",
    "print(f\"\\nShape de X (regressão): {X_reg.shape}\")\n",
    "print(f\"Shape de y (regressão): {y_reg.shape}\")\n",
    "print(f\"\\nEstatísticas do atraso:\")\n",
    "print(y_reg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split treino/teste para regressão\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train_reg.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test_reg.shape}\")\n",
    "\n",
    "# Normalização\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "print(\"\\n✓ Dados normalizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc124bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos de regressão\n",
    "regressors = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    'LightGBM': LGBMRegressor(n_estimators=100, random_state=RANDOM_STATE, verbose=-1)\n",
    "}\n",
    "\n",
    "print(f\"Modelos de regressão a serem treinados: {list(regressors.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ed45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar e avaliar modelos de regressão\n",
    "results_regression = {}\n",
    "\n",
    "for name, reg in regressors.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Treinando: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Treinar\n",
    "    if name in ['Linear Regression', 'Ridge']:\n",
    "        reg.fit(X_train_reg_scaled, y_train_reg)\n",
    "        y_pred_reg = reg.predict(X_test_reg_scaled)\n",
    "    else:\n",
    "        reg.fit(X_train_reg, y_train_reg)\n",
    "        y_pred_reg = reg.predict(X_test_reg)\n",
    "    \n",
    "    # Métricas\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "    \n",
    "    results_regression[name] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R²': r2,\n",
    "        'model': reg,\n",
    "        'predictions': y_pred_reg\n",
    "    }\n",
    "    \n",
    "    print(f\"MAE:  {mae:.2f} minutos\")\n",
    "    print(f\"MSE:  {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f} minutos\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Todos os modelos de regressão treinados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0853ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação de modelos de regressão\n",
    "comparison_reg_df = pd.DataFrame(results_regression).T\n",
    "comparison_reg_df = comparison_reg_df[['MAE', 'RMSE', 'R²']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAÇÃO DE MODELOS - REGRESSÃO\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_reg_df.round(2))\n",
    "\n",
    "# Visualização\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gráfico de barras\n",
    "comparison_reg_df[['MAE', 'RMSE']].plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Comparação de Erros - Modelos de Regressão', fontweight='bold', fontsize=14)\n",
    "axes[0].set_ylabel('Erro (minutos)')\n",
    "axes[0].set_xlabel('Modelo')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].set_xticklabels(comparison_reg_df.index, rotation=45, ha='right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# R² Score\n",
    "comparison_reg_df['R²'].plot(kind='bar', ax=axes[1], color='green')\n",
    "axes[1].set_title('R² Score - Modelos de Regressão', fontweight='bold', fontsize=14)\n",
    "axes[1].set_ylabel('R² Score')\n",
    "axes[1].set_xlabel('Modelo')\n",
    "axes[1].set_xticklabels(comparison_reg_df.index, rotation=45, ha='right')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de resíduos para o melhor modelo\n",
    "best_reg_model_name = comparison_reg_df['R²'].idxmax()\n",
    "best_reg_predictions = results_regression[best_reg_model_name]['predictions']\n",
    "\n",
    "print(f\"\\nMelhor modelo de regressão (por R²): {best_reg_model_name}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Valores preditos vs reais\n",
    "axes[0].scatter(y_test_reg, best_reg_predictions, alpha=0.3)\n",
    "axes[0].plot([y_test_reg.min(), y_test_reg.max()], \n",
    "             [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Atraso Real (minutos)', fontsize=12)\n",
    "axes[0].set_ylabel('Atraso Predito (minutos)', fontsize=12)\n",
    "axes[0].set_title(f'Predições vs Valores Reais - {best_reg_model_name}', \n",
    "                  fontweight='bold', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Resíduos\n",
    "residuals = y_test_reg - best_reg_predictions\n",
    "axes[1].scatter(best_reg_predictions, residuals, alpha=0.3)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Atraso Predito (minutos)', fontsize=12)\n",
    "axes[1].set_ylabel('Resíduos', fontsize=12)\n",
    "axes[1].set_title('Gráfico de Resíduos', fontweight='bold', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dc14f",
   "metadata": {},
   "source": [
    "## 2.6 Conclusões da Modelagem Supervisionada\n",
    "\n",
    "### Classificação (Prever se voo vai atrasar):\n",
    "- Comparamos 5 algoritmos diferentes\n",
    "- Métricas avaliadas: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
    "- Identificamos as features mais importantes para predição\n",
    "\n",
    "### Regressão (Prever tempo de atraso):\n",
    "- Testamos 6 modelos diferentes\n",
    "- Métricas avaliadas: MAE, RMSE, R²\n",
    "- Análise de resíduos para validar o modelo\n",
    "\n",
    "### Limitações:\n",
    "1. Possível desbalanceamento de classes na classificação\n",
    "2. Necessidade de mais features contextuais (clima, feriados, eventos)\n",
    "3. Possíveis outliers nos dados de atraso\n",
    "\n",
    "### Próximos Passos:\n",
    "1. Otimização de hiperparâmetros com GridSearch\n",
    "2. Tratamento de desbalanceamento com SMOTE/undersampling\n",
    "3. Feature engineering mais avançado\n",
    "4. Ensemble de modelos\n",
    "5. Análise de erros e casos extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados\n",
    "import pickle\n",
    "\n",
    "print(\"Salvando modelos e resultados...\")\n",
    "\n",
    "# Salvar melhor modelo de classificação\n",
    "with open('best_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(results_classification[best_model_name]['model'], f)\n",
    "print(f\"✓ Melhor classificador salvo: {best_model_name}\")\n",
    "\n",
    "# Salvar melhor modelo de regressão\n",
    "with open('best_regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(results_regression[best_reg_model_name]['model'], f)\n",
    "print(f\"✓ Melhor regressor salvo: {best_reg_model_name}\")\n",
    "\n",
    "# Salvar scalers\n",
    "with open('scaler_classification.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('scaler_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_reg, f)\n",
    "print(\"✓ Scalers salvos\")\n",
    "\n",
    "# Salvar resultados em CSV\n",
    "comparison_df.to_csv('classification_results.csv')\n",
    "comparison_reg_df.to_csv('regression_results.csv')\n",
    "print(\"✓ Resultados salvos em CSV\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELAGEM SUPERVISIONADA CONCLUÍDA!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
